"""
run_analysis.py - çµ±åˆè§£æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

PLXãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä½ç›¸ãƒ­ãƒƒã‚¯è§£æã¾ã§ã®å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
Jupyter Notebook ã§ã‚»ãƒ«ã”ã¨ã«å®Ÿè¡Œã€ã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦ä¸€æ‹¬å®Ÿè¡Œã€‚

=== å…¨ä½“ãƒ•ãƒ­ãƒ¼ ===

  PLX File
    â”‚
    â”œâ”€â†’ [Step 1] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (data_loader.py)
    â”‚     â””â”€â†’ RecordingSession
    â”‚
    â”œâ”€â†’ [Step 2] LFPå‡¦ç† (pipeline.py / processing.py)
    â”‚     â”œâ”€â†’ ãƒãƒ³ãƒ‰ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿
    â”‚     â”œâ”€â†’ ãƒãƒƒãƒãƒ•ã‚£ãƒ«ã‚¿
    â”‚     â”œâ”€â†’ ç’°å¢ƒãƒã‚¤ã‚ºé™¤å»
    â”‚     â”œâ”€â†’ ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆé™¤å» (ICA)
    â”‚     â””â”€â†’ lfp_cleaned
    â”‚
    â”œâ”€â†’ [Step 3] ã‚¹ãƒ‘ã‚¤ã‚¯ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚° (spike_sorting.py)
    â”‚     â”œâ”€â†’ è‡ªå‹•ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚° (GMM + BIC)
    â”‚     â”œâ”€â†’ GUIæ‰‹å‹•ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (spike_sorting_gui.py)
    â”‚     â””â”€â†’ sorting_results {ch: ChannelSortResult}
    â”‚
    â”œâ”€â†’ [Step 4] åˆºæ¿€å¿œç­”è§£æ (stimulus.py)
    â”‚     â”œâ”€â†’ PSTH
    â”‚     â”œâ”€â†’ Trialåˆ¥ãƒ©ã‚¹ã‚¿ãƒ¼
    â”‚     â”œâ”€â†’ é©å¿œè§£æ
    â”‚     â””â”€â†’ æ¡ä»¶ãƒã‚¹ã‚¯
    â”‚
    â”œâ”€â†’ [Step 5] ä½ç›¸ãƒ­ãƒƒã‚¯è§£æ (spike_lfp_analysis.py)
    â”‚     â”œâ”€â†’ å‘¨æ³¢æ•°å¸¯åŸŸåˆ¥ Ã— ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥
    â”‚     â”œâ”€â†’ æ¡ä»¶åˆ¥ï¼ˆBaseline/Stim/Postï¼‰
    â”‚     â”œâ”€â†’ STA (Spike Triggered Average)
    â”‚     â””â”€â†’ çµ±åˆã‚µãƒãƒªãƒ¼
    â”‚
    â””â”€â†’ [Step 6] ä¿å­˜ & å¯è¦–åŒ–
          â”œâ”€â†’ CSV (ä½ç›¸ãƒ­ãƒƒã‚¯çµæœ)
          â”œâ”€â†’ NPZ (ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°çµæœ)
          â””â”€â†’ PNG (ã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ)

ä½¿ã„æ–¹:
    # === Jupyter Notebook ===
    # å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚»ãƒ«ã”ã¨ã«å®Ÿè¡Œ

    # === ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ===
    python run_analysis.py --plx data.plx --output results/
"""

import numpy as np
import os
import sys
import warnings
warnings.filterwarnings('ignore')


# ============================================================
# Step 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ============================================================

def step1_load_data(plx_file, channel_order=None, verbose=True):
    """
    PLXãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€RecordingSessionã‚’è¿”ã™
    
    Parameters
    ----------
    plx_file : str
        PLXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    channel_order : list or None
        ãƒãƒ£ãƒ³ãƒãƒ«é †åºã€‚Noneã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€‚
    
    Returns
    -------
    session : RecordingSession
    """
    from data_loader import load_plx_session
    
    session = load_plx_session(plx_file, channel_order=channel_order, verbose=verbose)
    return session


# ============================================================
# Step 2: LFPå‡¦ç†
# ============================================================

def step2_process_lfp(session, config=None, use_gui=False, verbose=True):
    """
    LFPã®å‰å‡¦ç†ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ã€ãƒã‚¤ã‚ºé™¤å»ã€ICAï¼‰
    
    Parameters
    ----------
    session : RecordingSession
    config : PipelineConfig or None
        LFPãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šã€‚Noneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€‚
    use_gui : bool
        Trueã®å ´åˆã€config_gui.pyã®GUIã§è¨­å®š
    
    Returns
    -------
    lfp_result : dict
        {
            'lfp_cleaned': ndarray,
            'lfp_filtered': ndarray,
            'lfp_times': ndarray,
            'noise_mask': ndarray,
            'good_channels': list,
            'original_ch_numbers': list,
        }
    """
    from processing import (
        bandpass_notch_filter, detect_bad_channels,
        remove_known_harmonics,
    )
    
    log = print if verbose else lambda *a, **kw: None
    log("\n=== Step 2: LFP Processing ===")
    
    lfp_raw = session.lfp_raw
    fs = session.fs_lfp
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    if config is None:
        from pipeline import PipelineConfig
        config = PipelineConfig()
    
    # --- ãƒãƒ³ãƒ‰ãƒ‘ã‚¹ + ãƒãƒƒãƒ ---
    log(f"  Bandpass: {config.filter_lowcut}-{config.filter_highcut} Hz")
    notch = config.notch_freq if config.notch_enabled else None
    lfp_filtered, _ = bandpass_notch_filter(
        lfp_raw, config.filter_lowcut, config.filter_highcut, fs,
        filter_type=config.filter_type,
        order=config.filter_order,
        notch_freq=notch,
        notch_Q=config.notch_Q
    )
    
    # --- é«˜èª¿æ³¢é™¤å» ---
    if config.harmonic_removal_enabled:
        log(f"  Harmonic removal: {config.harmonic_fundamental}Hz fundamental")
        lfp_filtered, harmonics = remove_known_harmonics(
            lfp_filtered, fs,
            fundamental=config.harmonic_fundamental,
            n_harmonics=config.harmonic_count,
            Q=config.harmonic_q
        )
    
    # --- Bad channel detection ---
    bad_channels = []
    if config.bad_channel_detection:
        bad_channels, _ = detect_bad_channels(
            lfp_filtered, session.channel_order,
            threshold=config.bad_channel_threshold, verbose=verbose
        )
    bad_channels = list(set(bad_channels + config.manual_bad_channels))
    
    good_channels = [i for i in range(lfp_filtered.shape[1]) if i not in bad_channels]
    original_ch_numbers = [session.channel_order[i] for i in good_channels]
    
    lfp_filtered = lfp_filtered[:, good_channels]
    
    log(f"  Bad channels: {bad_channels}, remaining: {len(good_channels)}")
    
    # --- æ™‚é–“è»¸ ---
    lfp_times = np.arange(len(lfp_filtered)) / fs
    
    # --- ãƒã‚¤ã‚ºãƒã‚¹ã‚¯ï¼ˆãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³è§£æï¼‰ ---
    noise_mask = np.zeros(len(lfp_times), dtype=bool)
    
    video_file = session.get_video_path()
    if config.motion_analysis and os.path.exists(video_file) and len(session.frame_times) > 0:
        from processing import analyze_video_motion, create_noise_mask, remove_artifact_ica
        
        log("  Motion analysis...")
        motion_values, roi = analyze_video_motion(
            video_file, roi=config.motion_roi,
            threshold=config.motion_threshold_val
        )
        noise_mask, motion_resampled, motion_threshold = create_noise_mask(
            motion_values, session.frame_times, lfp_times, fs,
            percentile=config.motion_percentile
        )
        log(f"  Noise: {100*np.sum(noise_mask)/len(noise_mask):.1f}%")
        
        # ICA
        if config.ica_enabled and np.sum(noise_mask) > 0:
            log("  ICA artifact removal...")
            lfp_cleaned, removed_ics, _, _ = remove_artifact_ica(
                lfp_filtered, noise_mask,
                noise_ratio_threshold=config.ica_noise_ratio_threshold,
                max_remove=config.ica_max_remove, verbose=verbose
            )
            log(f"  Removed {len(removed_ics)} ICA components")
        else:
            lfp_cleaned = lfp_filtered.copy()
    else:
        lfp_cleaned = lfp_filtered.copy()
        log("  Motion analysis: skipped (no video)")
    
    log(f"  Final LFP: {lfp_cleaned.shape}")
    
    return {
        'lfp_cleaned': lfp_cleaned,
        'lfp_filtered': lfp_filtered,
        'lfp_times': lfp_times,
        'noise_mask': noise_mask,
        'good_channels': good_channels,
        'original_ch_numbers': original_ch_numbers,
        'fs': fs,
    }


# ============================================================
# Step 3: ã‚¹ãƒ‘ã‚¤ã‚¯ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
# ============================================================

def step3_spike_sorting(session, channels=None, config=None, 
                        curation='auto', auto_config=None,
                        verbose=True):
    """
    ã‚¹ãƒ‘ã‚¤ã‚¯ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚° + ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    
    Parameters
    ----------
    session : RecordingSession
    channels : list or None
        ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ãƒãƒ£ãƒ³ãƒãƒ«ã€‚Noneã§å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã€‚
    config : SortingConfig or None
    curation : str
        ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰:
          'auto'  â†’ åŸºæº–ãƒ™ãƒ¼ã‚¹ã§è‡ªå‹•åˆ†é¡ãƒ»ãƒãƒ¼ã‚¸ï¼ˆGUIãªã—ï¼‰
          'gui'   â†’ æ‰‹å‹•ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆGUIã®ã¿ã€è‡ªå‹•åˆ†é¡ãªã—ï¼‰
          'both'  â†’ è‡ªå‹•åˆ†é¡ã—ã¦ã‹ã‚‰GUIã§ç¢ºèªãƒ»å¾®èª¿æ•´
          'none'  â†’ ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼ˆç”Ÿã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®ã¾ã¾ï¼‰
    auto_config : AutoCurationConfig or None
        è‡ªå‹•ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šï¼ˆcuration='auto' or 'both' æ™‚ã®ã¿ï¼‰
    
    Returns
    -------
    sorting_results : dict {channel: ChannelSortResult}
    """
    from spike_sorting import (sort_channel, SortingConfig, bandpass_filter,
                                AutoCurationConfig, auto_curate_all)
    
    log = print if verbose else lambda *a, **kw: None
    log("\n=== Step 3: Spike Sorting ===")
    log(f"  Curation mode: {curation}")
    
    if config is None:
        config = SortingConfig()
    if auto_config is None:
        auto_config = AutoCurationConfig()
    
    wideband = session.wideband
    fs = session.fs_wideband
    
    if channels is None:
        channels = list(range(wideband.shape[1]))
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    log(f"  Bandpass: {config.filter_low}-{config.filter_high} Hz")
    filtered = bandpass_filter(wideband, fs, config.filter_low, config.filter_high, config.filter_order)
    
    # è‡ªå‹•ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆå…¨ãƒ¢ãƒ¼ãƒ‰å…±é€šï¼‰
    sorting_results = {}
    for ch in channels:
        log(f"\n  --- Channel {ch} ---")
        result = sort_channel(filtered[:, ch], fs, ch, config, verbose)
        sorting_results[ch] = result
    
    total_units = sum(len(r.units) for r in sorting_results.values())
    total_spikes = sum(sum(u.n_spikes for u in r.units) for r in sorting_results.values())
    log(f"\n  Clustering done: {total_units} units, {total_spikes} spikes")
    
    # --- ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---
    
    # è‡ªå‹•ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ'auto' or 'both'ï¼‰
    if curation in ('auto', 'both'):
        recording_duration = session.duration if hasattr(session, 'duration') else None
        summary = auto_curate_all(
            sorting_results, auto_config, config,
            recording_duration, verbose
        )
        log(f"\n  Auto-curation: {summary['total_su']} SU, "
            f"{summary['total_mua']} MUA, {summary['total_noise']} Noise")
    
    # GUIã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ'gui' or 'both'ï¼‰
    if curation in ('gui', 'both'):
        log("\n  Opening GUI for manual curation...")
        from spike_sorting_gui import SpikeSortingGUI
        gui = SpikeSortingGUI(sorting_results)
        gui.run()
        sorting_results = gui.results
    
    return sorting_results


def step3_load_sorting(filepath, verbose=True):
    """
    ä¿å­˜æ¸ˆã¿ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°çµæœã‚’èª­ã¿è¾¼ã‚€
    
    Parameters
    ----------
    filepath : str
        NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    Returns
    -------
    sorting_results : dict {channel: ChannelSortResult}
    """
    from data_loader import load_sorting_results
    
    if verbose:
        print(f"\n=== Step 3: Load Sorting Results ===")
    
    return load_sorting_results(filepath)


# ============================================================
# Step 4: åˆºæ¿€å¿œç­”è§£æ
# ============================================================

def step4_stimulus_analysis(session, sorting_results, lfp_result=None,
                             verbose=True):
    """
    åˆºæ¿€å¿œç­”è§£æ
    
    Parameters
    ----------
    session : RecordingSession
    sorting_results : dict
    lfp_result : dict or None
        step2ã®å‡ºåŠ›ï¼ˆSTAã«ä½¿ç”¨ï¼‰
    
    Returns
    -------
    protocol : StimulusProtocol
    stim_results : dict {unit_key: {psth, adaptation, ...}}
    """
    from stimulus import StimulusProtocol
    
    log = print if verbose else lambda *a, **kw: None
    log("\n=== Step 4: Stimulus Response Analysis ===")
    
    # ãƒ—ãƒ­ãƒˆã‚³ãƒ«ä½œæˆ
    protocol = StimulusProtocol(
        stim_times=session.stim_times,
        trial_starts=session.trial_starts,
        n_stim_per_trial=session.n_stim_per_trial,
        stim_freq=session.stim_freq,
        iti=session.iti
    )
    log(f"  {protocol}")
    
    # å„ãƒ¦ãƒ‹ãƒƒãƒˆã®è§£æ
    stim_results = {}
    
    for ch, result in sorting_results.items():
        for unit in result.units:
            if unit.is_noise:
                continue
            
            unit_key = f"ch{ch}_unit{unit.unit_id}"
            log(f"\n  {unit_key} (n={unit.n_spikes}):")
            
            # PSTH
            psth = protocol.compute_psth(unit.spike_times)
            log(f"    PSTH: peak={psth.peak_latency_ms:.1f}ms, "
                f"rate={psth.peak_rate:.1f}Hz")
            
            # Adaptation
            adapt = protocol.compute_adaptation(unit.spike_times)
            log(f"    Adaptation ratio: {adapt.adaptation_ratio:.2f}")
            
            stim_results[unit_key] = {
                'psth': psth,
                'adaptation': adapt,
                'spike_times': unit.spike_times,
            }
    
    return protocol, stim_results


# ============================================================
# Step 5: ä½ç›¸ãƒ­ãƒƒã‚¯è§£æ
# ============================================================

def step5_phase_locking(sorting_results, lfp_result, protocol=None,
                         freq_bands=None, min_spikes=50, verbose=True):
    """
    ä½ç›¸ãƒ­ãƒƒã‚¯è§£æ
    
    Parameters
    ----------
    sorting_results : dict
    lfp_result : dict
        step2ã®å‡ºåŠ›
    protocol : StimulusProtocol or None
    freq_bands : dict or None
    min_spikes : int
    
    Returns
    -------
    analyzer : SpikeLFPAnalyzer
    """
    from spike_lfp_analysis import SpikeLFPAnalyzer
    
    log = print if verbose else lambda *a, **kw: None
    log("\n=== Step 5: Phase-Locking Analysis ===")
    
    analyzer = SpikeLFPAnalyzer(
        lfp_data=lfp_result['lfp_cleaned'],
        lfp_times=lfp_result['lfp_times'],
        fs_lfp=lfp_result['fs'],
        sorting_results=sorting_results,
        protocol=protocol,
        noise_mask=lfp_result.get('noise_mask'),
        freq_bands=freq_bands,
    )
    
    # å…¨ãƒ¦ãƒ‹ãƒƒãƒˆè§£æ
    results = analyzer.analyze_all(min_spikes=min_spikes, verbose=verbose)
    
    return analyzer


# ============================================================
# Step 6: ä¿å­˜ & å¯è¦–åŒ–
# ============================================================

def step6_save_and_plot(analyzer, sorting_results, protocol, 
                         output_dir, basename=None, verbose=True):
    """
    çµæœã®ä¿å­˜ã¨å¯è¦–åŒ–
    
    Parameters
    ----------
    analyzer : SpikeLFPAnalyzer
    sorting_results : dict
    protocol : StimulusProtocol
    output_dir : str
    basename : str or None
    """
    from spike_sorting import save_sorting_results, export_spike_times_csv
    
    log = print if verbose else lambda *a, **kw: None
    log("\n=== Step 6: Save & Visualize ===")
    
    os.makedirs(output_dir, exist_ok=True)
    basename = basename or "analysis"
    
    # --- ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°çµæœ ---
    sorting_path = os.path.join(output_dir, f'{basename}_sorting.npz')
    save_sorting_results(sorting_results, sorting_path)
    log(f"  Sorting: {sorting_path}")
    
    spikes_csv = os.path.join(output_dir, f'{basename}_spike_times.csv')
    export_spike_times_csv(sorting_results, spikes_csv)
    log(f"  Spike times: {spikes_csv}")
    
    # --- ä½ç›¸ãƒ­ãƒƒã‚¯çµæœ ---
    analyzer.save_results_csv(output_dir, basename)
    
    # --- ãƒ¦ãƒ‹ãƒƒãƒˆã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ ---
    log("\n  Generating summary plots...")
    
    plot_dir = os.path.join(output_dir, 'plots')
    os.makedirs(plot_dir, exist_ok=True)
    
    for unit_key, pl_result in analyzer.unit_results.items():
        save_path = os.path.join(plot_dir, f'{unit_key}_summary.png')
        try:
            analyzer.plot_unit_summary(
                pl_result.channel, pl_result.unit_id,
                save_path=save_path
            )
            import matplotlib.pyplot as plt
            plt.close()
        except Exception as e:
            log(f"    Warning: {unit_key} plot failed: {e}")
    
    # --- é›†å›£ã‚µãƒãƒªãƒ¼ ---
    pop_path = os.path.join(plot_dir, f'{basename}_population_summary.png')
    try:
        analyzer.plot_population_summary(save_path=pop_path)
        import matplotlib.pyplot as plt
        plt.close()
    except Exception as e:
        log(f"    Warning: population plot failed: {e}")
    
    # --- åˆºæ¿€å¿œç­”ãƒ—ãƒ­ãƒƒãƒˆ ---
    if protocol is not None:
        for ch, result in sorting_results.items():
            for unit in result.units:
                if unit.is_noise:
                    continue
                unit_key = f"ch{ch}_unit{unit.unit_id}"
                stim_path = os.path.join(plot_dir, f'{unit_key}_stimulus.png')
                try:
                    protocol.plot_summary(
                        unit.spike_times,
                        lfp_data=analyzer.lfp_data,
                        lfp_times=analyzer.lfp_times,
                        fs=analyzer.fs_lfp,
                        save_path=stim_path
                    )
                    import matplotlib.pyplot as plt
                    plt.close()
                except Exception as e:
                    log(f"    Warning: {unit_key} stimulus plot failed: {e}")
    
    log(f"\n  All results saved to: {output_dir}")
    return output_dir


# ============================================================
# Step 7: å…¨ãƒãƒ£ãƒ³ãƒãƒ«çµ±åˆè§£æ
# ============================================================

def step7_comprehensive(session, lfp_result, sorting_results,
                         protocol=None, analyzer=None,
                         output_dir=None, verbose=True):
    """
    å…¨ãƒãƒ£ãƒ³ãƒãƒ«æ¨ªæ–­ã®çµ±åˆè§£æ

    - ã‚¹ãƒ‘ã‚¤ã‚¯ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ¦‚è¦ï¼ˆæ³¢å½¢ä¸€è¦§ãƒ»å“è³ªãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ç™ºç«ç‡æ·±åº¦ï¼‰
    - LFPæ·±åº¦è§£æï¼ˆCSDãƒ»ãƒ‘ãƒ¯ãƒ¼æ·±åº¦ãƒ»ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ï¼‰
    - ä½ç›¸ãƒ­ãƒƒã‚¯æ·±åº¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    - ã‚°ãƒ©ãƒ³ãƒ‰ã‚µãƒãƒªãƒ¼
    - ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ

    Parameters
    ----------
    session : RecordingSession
    lfp_result : dict
        step2 ã®å‡ºåŠ›
    sorting_results : dict
        step3 ã®å‡ºåŠ›
    protocol : StimulusProtocol or None
    analyzer : SpikeLFPAnalyzer or None
        step5 ã®å‡ºåŠ›
    output_dir : str or None
        ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns
    -------
    ca : ComprehensiveAnalyzer
    """
    from comprehensive_analysis import ComprehensiveAnalyzer

    log = print if verbose else lambda *a, **kw: None
    log("\n=== Step 7: Comprehensive Cross-Channel Analysis ===")

    ca = ComprehensiveAnalyzer(
        session=session,
        lfp_result=lfp_result,
        sorting_results=sorting_results,
        protocol=protocol,
        spike_lfp_analyzer=analyzer,
    )

    if output_dir:
        comp_dir = os.path.join(output_dir, 'comprehensive')
        ca.save_all(comp_dir, verbose=verbose)

    return ca


# ============================================================
# å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
# ============================================================

def run_full_pipeline(plx_file, output_dir=None, channel_order=None,
                      sorting_file=None, sort_channels=None,
                      curation='auto', auto_config=None,
                      freq_bands=None, verbose=True):
    """
    å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¸€æ‹¬å®Ÿè¡Œ
    
    Parameters
    ----------
    plx_file : str
        PLXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    output_dir : str or None
        å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚Noneã§PLXã¨åŒã˜å ´æ‰€ã€‚
    channel_order : list or None
        ãƒãƒ£ãƒ³ãƒãƒ«é †åº
    sorting_file : str or None
        ä¿å­˜æ¸ˆã¿ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°çµæœã€‚Noneã§æ–°è¦ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€‚
    sort_channels : list or None
        ã‚½ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ãƒãƒ£ãƒ³ãƒãƒ«
    curation : str
        'auto', 'gui', 'both', 'none'
    auto_config : AutoCurationConfig or None
        è‡ªå‹•ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
    freq_bands : dict or None
        ä½ç›¸ãƒ­ãƒƒã‚¯è§£æã®å‘¨æ³¢æ•°å¸¯åŸŸ
    verbose : bool
    
    Returns
    -------
    results : dict
        å…¨ã‚¹ãƒ†ãƒƒãƒ—ã®çµæœ
    """
    if output_dir is None:
        output_dir = os.path.join(os.path.dirname(plx_file), 'analysis_output')
    
    basename = os.path.splitext(os.path.basename(plx_file))[0]
    
    # Step 1
    session = step1_load_data(plx_file, channel_order, verbose)
    
    # Step 2
    lfp_result = step2_process_lfp(session, verbose=verbose)
    
    # Step 3
    if sorting_file and os.path.exists(sorting_file):
        sorting_results = step3_load_sorting(sorting_file, verbose)
        # ãƒ­ãƒ¼ãƒ‰å¾Œã‚‚è‡ªå‹•ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨å¯èƒ½
        if curation in ('auto', 'both'):
            from spike_sorting import AutoCurationConfig, auto_curate_all
            if auto_config is None:
                auto_config = AutoCurationConfig()
            recording_duration = session.duration if hasattr(session, 'duration') else None
            auto_curate_all(sorting_results, auto_config,
                            recording_duration=recording_duration, verbose=verbose)
    else:
        sorting_results = step3_spike_sorting(
            session, channels=sort_channels,
            curation=curation, auto_config=auto_config,
            verbose=verbose
        )
    
    # Step 4
    protocol, stim_results = step4_stimulus_analysis(
        session, sorting_results, lfp_result, verbose
    )
    
    # Step 5
    analyzer = step5_phase_locking(
        sorting_results, lfp_result, protocol, freq_bands, verbose=verbose
    )
    
    # Step 6
    step6_save_and_plot(analyzer, sorting_results, protocol, output_dir, basename, verbose)
    
    # Step 7: å…¨ãƒãƒ£ãƒ³ãƒãƒ«çµ±åˆè§£æ
    ca = step7_comprehensive(
        session, lfp_result, sorting_results,
        protocol=protocol, analyzer=analyzer,
        output_dir=output_dir, verbose=verbose
    )
    
    results = {
        'session': session,
        'lfp_result': lfp_result,
        'sorting_results': sorting_results,
        'protocol': protocol,
        'stim_results': stim_results,
        'analyzer': analyzer,
        'comprehensive': ca,
    }
    
    return results


# ============================================================
# Step 8: è§£æã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ© GUI
# ============================================================

def step8_explorer(session, lfp_result, sorting_results,
                   protocol=None, sla=None, ca=None):
    """
    ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è§£æã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©GUIã‚’èµ·å‹•
    
    å…¨è§£æçµæœã‚’ã‚¿ãƒ–å½¢å¼ã§æ¢ç´¢ï¼š
      - ğŸ§  ã‚¹ãƒ‘ã‚¤ã‚¯æ¦‚è¦: å“è³ªãƒ†ãƒ¼ãƒ–ãƒ« + æ³¢å½¢ä¸€è¦§ + 9ãƒ‘ãƒãƒ«è©³ç´°
      - ğŸ“Š LFPè§£æ: å…¨chæ³¢å½¢ + PSD + CSD + ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
      - ğŸ”— çµ±åˆè§£æ: ä½ç›¸ãƒ­ãƒƒã‚¯ Ã— æ·±åº¦ + STA + æ¡ä»¶åˆ¥MRL  
      - ğŸ’¾ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: PNG/CSVä¸€æ‹¬ä¿å­˜
    
    Parameters
    ----------
    session : RecordingSession
    lfp_result : dict
    sorting_results : dict
    protocol : StimulusProtocol, optional
    sla : SpikeLFPAnalyzer, optional
    ca : ComprehensiveAnalyzer, optional
    """
    from analysis_gui import launch_explorer
    return launch_explorer(
        session, lfp_result, sorting_results,
        protocol=protocol, sla=sla, ca=ca
    )


def launch_explorer_from_results(results):
    """
    run_full_pipeline() ã®æˆ»ã‚Šå€¤ã‹ã‚‰ç›´æ¥GUIã‚’èµ·å‹•
    
    Usage:
        results = run_full_pipeline(...)
        launch_explorer_from_results(results)
    """
    return step8_explorer(
        session=results['session'],
        lfp_result=results['lfp_result'],
        sorting_results=results['sorting_results'],
        protocol=results.get('protocol'),
        sla=results.get('analyzer'),
        ca=results.get('comprehensive'),
    )


# ============================================================
# CLI
# ============================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Neuronexus Analysis Pipeline")
    parser.add_argument("--plx", required=True, help="PLX file path")
    parser.add_argument("--output", default=None, help="Output directory")
    parser.add_argument("--sorting", default=None, help="Pre-sorted NPZ file")
    parser.add_argument("--channels", nargs='+', type=int, default=None,
                       help="Channels to sort")
    parser.add_argument("--curation", choices=['auto', 'gui', 'both', 'none'],
                       default='auto',
                       help="Curation mode: auto/gui/both/none (default: auto)")
    parser.add_argument("--gui", action="store_true",
                       help="Launch Analysis Explorer GUI after pipeline")
    parser.add_argument("--quiet", action="store_true", help="Minimal output")
    
    args = parser.parse_args()
    
    results = run_full_pipeline(
        plx_file=args.plx,
        output_dir=args.output,
        sorting_file=args.sorting,
        sort_channels=args.channels,
        curation=args.curation,
        verbose=not args.quiet,
    )
    
    if args.gui:
        print("\nLaunching Analysis Explorer GUI ...")
        launch_explorer_from_results(results)
    
    print("\nDone!")
